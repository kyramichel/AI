{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c68730",
   "metadata": {},
   "source": [
    "## LSTM  \n",
    "\n",
    "for sequence of words prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701e10d",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf366d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8bcc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Thanks for doing what you do. \n",
    "\n",
    "Thank you so much. \n",
    "\n",
    "The work you do is important and so appreciated. \n",
    "\n",
    "Sending appreciation your way today.\n",
    "\n",
    "Just wanted to express our deep gratitude for the dedicated work you do day after day.\n",
    "\n",
    "For all you do—and for the kind, thoughtful way you do it—thank you.\n",
    "        \n",
    "We could never take for granted the hard work you do. We see it, and we appreciate you.\n",
    "\n",
    "Thank you for your friendly, dependable service through every season.\n",
    "\n",
    "Thank you for going the extra mile for all of us who depend on you.”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556a14c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks for doing what you do. Thank so much. The work do is important and appreciated. Sending appreciation your way today. Just wanted to express our deep gratitude the dedicated day after day. For all do—and kind, thoughtful it—thank you. We could never take granted hard see it, we appreciate friendly, dependable service through every season. going extra mile of us who depend on you.”'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = []\n",
    "\n",
    "for i in text.split():\n",
    "    if i not in z:\n",
    "        z.append(i)\n",
    "        \n",
    "data = ' '.join(z)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319a74fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d67fe6",
   "metadata": {},
   "source": [
    "Preprocessing data \n",
    "\n",
    "\n",
    "Tokenizing the text, creating the input-output datasets X and y of predictive model, and converting the predictions y into categorical data as follows:\n",
    "\n",
    "\n",
    "Using Keras Tokenizer to vectorize the text + convert the texts to sequences \n",
    "\n",
    "Creating the training dataset X that contains the training data with the input of text data\n",
    "\n",
    "and y that will contain the outputs: the next word predictions for each input ‘X’\n",
    "\n",
    "Compute the vocab_size - using the length extracted from tokenizer.word_index + 1 (adding 1 because 0 is a reserved for padding and we want to start our count from 1) \n",
    "\n",
    "Convert predictions data Y to categorical data of the vocab size  - a function that converts a class vector (integers) to the binary representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984ad30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = []\n",
    "\n",
    "for i in range(1, len(sequence_data)):\n",
    "    words = sequence_data[i-1:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0])\n",
    "    y.append(i[1])\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(y)\n",
    "\n",
    "Y = to_categorical(Y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325fd39",
   "metadata": {},
   "source": [
    "LSTM model design:\n",
    "\n",
    "A sequential model and adding layers, specifing the input and output dimensions. \n",
    "\n",
    "The input length = 1 since the prediction will be made on exactly one word and we will receive a response for that particular word. Add an LSTM layer with 100 neurons. Return the sequences as true to ensure that we can pass it through another LSTM layer. Next LSTM layer with another 100 units but no need to specify return sequence as we will pass this through a hidden layer with 100 nodes using the Dense layer with activation ReLu. The output layer with Softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d221f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "model.fit(X, Y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0e85c",
   "metadata": {},
   "source": [
    "Making predictions using predict_classes() based on the trained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eed54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    \n",
    "    for i in range(3):\n",
    "        sequence = np.array(sequence_data)\n",
    "        preds = model.predict_classes(sequence)\n",
    "\n",
    "        predicted_word = \"\"\n",
    "        \n",
    "        for key, value in tokenizer.word_index.items():\n",
    "            if value == preds:\n",
    "                predicted_word = key\n",
    "                break\n",
    "        \n",
    "        print(predicted_word)\n",
    "        return predicted_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fce76",
   "metadata": {},
   "source": [
    "When user inputs a sequence, the trained LSTM model will try to predict a word.\n",
    "\n",
    "If no prediction can be made, just continue. You may change the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e650e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    text = input(\"Enter sequence of words: \")\n",
    "    try:\n",
    "        text = text.split(\" \")\n",
    "        text = text[-1]\n",
    "        text = ''.join(text)\n",
    "        predict(model, text)        \n",
    "    except:\n",
    "        continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e51a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
